# app.py
import os
import json
import math
import base64
from io import BytesIO
from datetime import datetime

import streamlit as st
import requests
from dotenv import load_dotenv
from mistralai import Mistral
from groq import Groq

# Charger les variables dâ€™environnement
load_dotenv()

GROQ_API_KEY     = os.getenv("GROQ_API_KEY")
MISTRAL_API_KEY  = os.getenv("MISTRAL_API_KEY")
CLIPDROP_API_KEY = os.getenv("CLIPDROP_API_KEY")

# VÃ©rification
if not all([GROQ_API_KEY, MISTRAL_API_KEY, CLIPDROP_API_KEY]):
    st.error("âŒ ClÃ©s API manquantes. VÃ©rifie ton fichier .env.")
    st.stop()

# Prompt dâ€™analyse Ã©motionnelle
PROMPT_EMOTION = """
Tu es un assistant dâ€™analyse dâ€™Ã©motions. 
Tu dois renvoyer STRICTEMENT un objet JSON, sans texte explicatif, contenant six scores
numÃ©riques entre 0 et 1 (inclus) pour :
heureux, anxieux, triste, en_colere, fatigue, apeure.
Attention l'utilisateur peut faire preuve d'ironie.
Aucun autre champ, commentaire ou formatage nâ€™est autorisÃ©.
"""

# Fonctions utilitaires
def softmax(pred):
    exp = {k: math.exp(v * 10) for k, v in pred.items()}
    total = sum(exp.values())
    return {k: round(v / total, 3) for k, v in exp.items()}

def transcribe(audio_bytes):
    client = Groq(api_key=GROQ_API_KEY)
    with open("temp_audio.wav", "wb") as f:
        f.write(audio_bytes.getvalue())
    with open("temp_audio.wav", "rb") as f:
        transcription = client.audio.transcriptions.create(
            file=f,
            model="whisper-large-v3-turbo",
            response_format="verbose_json",
            language="fr"
        )
    return transcription.text

def analyse_emotion(text):
    client = Mistral(api_key=MISTRAL_API_KEY)
    response = client.chat.complete(
        model="mistral-small",
        messages=[
            {"role": "system", "content": PROMPT_EMOTION},
            {"role": "user",   "content": f"Analyse ce texte : {text}"}
        ],
    )
    raw = json.loads(response.choices[0].message.content)
    return softmax(raw)

def generate_image(prompt):
    prompt = prompt.strip().replace("\n", " ")[:400]
    headers = {
        "x-api-key": CLIPDROP_API_KEY,
        "Content-Type": "application/json"
    }
    response = requests.post("https://clipdrop-api.co/text-to-image/v1", headers=headers, json={"prompt": prompt})
    if response.status_code != 200:
        st.error(f"Erreur Clipdrop : {response.status_code} â€“ {response.text}")
        response.raise_for_status()
    return response.content

def save_dream(text, emotions, image_bytes):
    img_b64 = base64.b64encode(image_bytes).decode('utf-8')
    record = {
        "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "texte": text,
        "emotions": emotions,
        "image_b64": img_b64
    }
    dreams = []
    if os.path.exists("dreams.json"):
        with open("dreams.json", "r") as f:
            dreams = json.load(f)
    dreams.append(record)
    with open("dreams.json", "w") as f:
        json.dump(dreams, f, indent=2)

def show_dashboard():
    st.header("ğŸ“Š Tableau de bord des rÃªves")
    if not os.path.exists("dreams.json"):
        st.info("Aucun rÃªve enregistrÃ© pour le moment.")
        return
    with open("dreams.json", "r") as f:
        dreams = json.load(f)
    for d in reversed(dreams):
        with st.expander(f"ğŸ—“ï¸ {d['date']}"):
            st.text_area("Texte du rÃªve", d["texte"], height=100, key=f"text_{d['date']}")
            st.json(d["emotions"])
            st.image(base64.b64decode(d["image_b64"]), caption="Image gÃ©nÃ©rÃ©e")

# Interface Streamlit
st.set_page_config(page_title="SynthÃ©tiseur de rÃªves", page_icon="ğŸ’¤")
st.title("ğŸ’¤ SynthÃ©tiseur de rÃªves")

page = st.sidebar.selectbox("Navigation", ["SynthÃ©tiseur", "Tableau de bord", "Aide"])

if page == "SynthÃ©tiseur":
    audio_option = st.radio("Saisir votre rÃªve :", ("Uploader un fichier audio", "Enregistrer l'audio"))
    audio_data = None

    if audio_option == "Uploader un fichier audio":
        file = st.file_uploader("TÃ©lÃ©chargez un fichier audio (.wav, .mp3 ou .m4a)", type=["wav", "mp3", "m4a"])
        if file:
            audio_data = BytesIO(file.read())
            st.audio(audio_data)
            st.success("âœ… Fichier audio chargÃ©")
    else:
        recorded = st.audio_input("Enregistrez votre rÃªve")
        if recorded:
            audio_data = BytesIO(recorded.getvalue())
            st.audio(audio_data)
            st.success("âœ… Audio enregistrÃ©")

    if audio_data:
        st.info("ğŸ§ Transcription...")
        text = transcribe(audio_data)
        st.text_area("Texte extrait", text, height=150)

        st.info("ğŸ§  Analyse des Ã©motions...")
        emotions = analyse_emotion(text)
        st.json(emotions)

        st.info("ğŸ¨ GÃ©nÃ©ration de lâ€™image...")
        img = generate_image(text)
        st.image(img, caption="Image du rÃªve gÃ©nÃ©rÃ©e")

        save_dream(text, emotions, img)
        st.success("ğŸ’¾ RÃªve sauvegardÃ© !")

elif page == "Tableau de bord":
    show_dashboard()

elif page == "Aide":
    st.header("â“ Aide - SynthÃ©tiseur de rÃªves")
    st.markdown("""
Bienvenue dans le SynthÃ©tiseur de rÃªves !

### ğŸ§¾ Mode dâ€™emploi
1. Allez dans **SynthÃ©tiseur**
2. Enregistrez ou importez votre rÃªve
3. Lâ€™IA :
   - transcrit,
   - analyse les Ã©motions,
   - gÃ©nÃ¨re une image,
   - sauvegarde tout.

### ğŸ“Š Tableau de bord
Tous vos rÃªves sont listÃ©s dans **Tableau de bord**

### ğŸ” DonnÃ©es
Les rÃªves sont enregistrÃ©s localement dans `dreams.json`

""")
